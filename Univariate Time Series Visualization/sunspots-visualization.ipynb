{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #data visualization\nimport seaborn as sns  #data visualization\nfrom scipy import stats #Stats library\nfrom pylab import rcParams\n\n\n#Matplotlib runtime(rc) configuration options\nrcParams['figure.figsize'] = 11, 9\n\n\n\n#Coerce warning issues\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n#importing time-based libraries\nimport time\nfrom datetime import time\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n#Libraries for statistical visualization in time-series\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Manipulating time series data**","metadata":{}},{"cell_type":"code","source":"#Some of the resourceful methods are pd.to_datetime(convert data type to datettime), pd.asfreq(for resampling) and pd.date_range(a range of dates)\n#Typical time-series shifting may include - shifting or lagging values back or forward in time, getting the values for a given time period, and computing the percent change\n#over many number of periods","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading in the data and basic formatting**","metadata":{}},{"cell_type":"code","source":"sunspots = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv', sep=',', parse_dates=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots['Month'] = pd.to_datetime(sunspots['Month'])\nsunspots.set_index('Month')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization of a time-series, and summary stats and diagnostics","metadata":{}},{"cell_type":"code","source":"med_value = sunspots['Sunspots'].median()\nquant_25 = sunspots['Sunspots'].quantile(0.25)\nquant_99 = sunspots['Sunspots'].quantile(0.99)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting up the style of background grid\nfig = plt.figure()\nplt.style.use('fivethirtyeight')\nax = sunspots['Sunspots'].plot(color='blue', fontsize=10, figsize=(10, 8))\n\n\n#A horizontal span\nax.axvspan(quant_25, quant_99, color='green', alpha=0.3)\n\n#A vertical span\nax.axhspan(30, 150, color='red', alpha=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking if there are any null values\nsunspots.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There aren't any null values in the dataframe","metadata":{}},{"cell_type":"markdown","source":"**Window Functions:**\n1. Used to identify sub-periods, calculates sub-metrics of sub-periods.\n2. Rolling - same size and sliding\n3. Expanding - includes all previous values","metadata":{}},{"cell_type":"code","source":"#Setting the index back to datetime format\nsunspots = sunspots.set_index('Month')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Rolling mean visualizations of some section of data, say from 1749 to 1753, unable to understand the concept\nsunSome_part = sunspots[1749 : 1753]\n\n\nsunSome_mean1 = sunSome_part.rolling(1).mean() #rolling mean for a single month\nsunSome_mean2 = sunSome_part.rolling(2).mean() #rolling mean for 2 consecutive months\nsunSome_mean3 = sunSome_part.rolling(3).mean() #rolling mean for a period of 3 months\n\n# ax = sunSome_mean1.plot()\n# ax.set_xlabel('Date')\n# ax.set_ylabel('Rolling Mean Variation')\n# ax.set_title('SPOT statistics')\n\nplt.style.use('fivethirtyeight')\nfig, ax = plt.subplots(1, figsize=(10, 5))\n\nax.plot(sunSome_mean1, sunSome_mean1.index, linewidth=2, markersize=12, color='green')\nax.plot(sunSome_mean2, sunSome_mean2.index, linewidth=2, markersize=12, color='blue')\nax.plot(sunSome_mean3, sunSome_mean3.index, linewidth=2, markersize=12, color='red')\n\nplt.title('Plotting out the rolling mean statistics')\nplt.xlabel('Susnpots Mean')\nplt.ylabel('Period')\nplt.legend(['1Day', '2Day', '3Day'])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's plot a more compact representation of our data. Here we will be computing rolling avergae for a lagging period of 2 months, i.e, 60 days.\n#ma variable is for moving avergaes\nma = sunspots.rolling(window=2).mean()\nmstd = sunspots.rolling(window=2).std()\n\n#Adding the lower bound\nma['Lower'] = ma['Sunspots'] - (2 * mstd['Sunspots'])\n\n#Adding the upper bound\nma['Upper'] = ma['Sunspots'] + (2 * mstd['Sunspots'])\n\n#Plot the dataframe and set the labels\nplt.figure(figsize=(10, 5))\n\nax = ma.plot(linewidth=0.8, fontsize=6)\nplt.xlabel('Date')\nplt.ylabel('Number of sunspots')\nplt.xlabel('Date')\nplt.title('Rolling mean and variance of the number of sunspots over the given period of time')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plotting aggregate values of a time series**","metadata":{}},{"cell_type":"code","source":"#For our use-case, let's try to plot the aggregate values for the number of spots in the year 1750\nsunspots_1750 = sunspots.iloc[sunspots.index.year==1750, : ]\nindex_month = sunspots.index.month\nsunspots_1750_by_month = sunspots.groupby(index_month).Sunspots.mean()\n\nsunspots_1750_by_month.plot()\nplt.ylabel('Cases per month')\nplt.legend('Sunspots', loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hence from the above visualization we can infer that the number of sunspots is at peak during the summer months,  which could be predetermindedly hypothesised.","metadata":{}},{"cell_type":"markdown","source":"Summarizing and plotting summary statistics","metadata":{}},{"cell_type":"code","source":"#Describing the dataframe\nprint(sunspots.describe())\n\n#Minmimum value\nprint(sunspots['Sunspots'].min())\n\n#Maximum value\nprint(sunspots['Sunspots'].max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing out the boxplot for visualizing summary statistics\nboxplot = sunspots.boxplot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots_copy = sunspots.copy()\nsunspots_copy.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sunspots_copy.rename(columns={'Month':'Date'}, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing out the boxplot for visualizing summary statistics\nboxplot = sunspots_copy.boxplot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We observe there are outliers in the upper half of boxplot. Let's reassign the outlier values to be equal to the upper half of the boxplot.\nupper_perc = sunspots_copy['Sunspots'].quantile(0.75)\nlower_perc = sunspots_copy['Sunspots'].quantile(0.25)\n\nupper_limit = upper_perc + (3 * upper_perc)\nlower_limit = lower_perc - (3 * lower_perc)\n\nprint(upper_limit)\nprint(lower_limit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#If the value of skewness is above 1, then it means there exists a positive skewness.\nsunspots_copy['Sunspots'].skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Histograms and Kernel Density Estimations(KDE):","metadata":{}},{"cell_type":"code","source":"sunspots['Sunspots'].plot(kind='hist', bins=100)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In practice, histograms can be a substandard method for assessing the distribution of your data because they can be strongly affected by the number of bins that have been specified. Instead, kernel density plots represent a more effective way to view the distribution of your data. An example of how to generate a density plot of is shown below:","metadata":{}},{"cell_type":"code","source":"ax = sunspots['Sunspots'].plot(kind='density', linewidth=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Since the distribution isn't normal, we will perform the following the quantile-based imputation\n#sunspots_copy[sunspots_copy['Sunspots'] > upper_limit] = upper_limit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There are a lot of negative values in the dataset. We need to remove them for the transformation to happen\n#sunspots_copy['Sunspots-1'] = sunspots_copy[sunspots_copy['Sunspots'] > 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Log-trasnform for removing left skewness\n#sunspots_copy['Sunspots-1'] = np.log1p(sunspots_copy['Sunspots-1'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sunspots_copy['Sunspots-1'].plot(kind='hist', bins=100)\n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sunspots_copy.drop(['Sunspots'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sunspots_copy['Sunspots-1'].plot(kind='kde')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting autocorrelation and autocorrelation","metadata":{}},{"cell_type":"code","source":"#Plotting autocorrelation\n#Lags and alpha are the only important parameters in these plots\nfig = plot_acf(sunspots_copy['Sunspots'], lags=20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting partial autocorrelation\n#Lags and alpha are the only important parameters in these plots\nfig = plot_pacf(sunspots_copy['Sunspots'], lags=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Like autocorrelation, the partial autocorrelation function also measures the correlation coefficient between a time series and a lagged version of itself. But\nthe main difference between the two is that PACF smoothens(lessens variations) the effect of lags beyond the ones explicitly mentioned.","metadata":{}},{"cell_type":"markdown","source":"**Time Series Decomposition** - for visualizing trend, seasonality and noise","metadata":{}},{"cell_type":"code","source":"rcParams['figure.figsize'] = 11, 9\n\ndecomposition = seasonal_decompose(sunspots['Sunspots'])\nfigure = decomposition.plot()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dir(decomposition))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(decomposition.seasonal)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time Series decomposition is a powerful tool to reveal the structure in a time-series.","metadata":{}},{"cell_type":"code","source":"#A seasonal component(cyclic component) exists when a time-series is influenced by seasonal factors. \ndecomp_seasonal = decomposition.resid\nax = decomp_seasonal.plot(figsize=(14, 10))\nax.set_xlabel('Date')\nax.set_ylabel('Seasonality')\nax.set_title('Seasonal values of the time series')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So far we have known:\n1. Visualize aggregates of time series data\n2. Extract statistical summaries\n3. Autocorrelation and Partial autocorrelation\n4. Time Series decomposition.","metadata":{}},{"cell_type":"markdown","source":"Multiple time-****series plots - refer the course","metadata":{}},{"cell_type":"markdown","source":"**Also you can print out the relationships between different time series data using heatmaps and clustered heatmaps.**\n1. Create facetted plots and graphs(using the pandas .plot function and setting up the layout of plots\n2. Set horiziontal/vertical lines/regions to specify/highlight some important year/date. This is ideal for a multiple time-series dataset.\n3. Aggregate plots are also ideal for a time-series dataset. (Monthly or yearly trends) alongwith bbox_to_anchor)\n4. Seasonal decomposition of multiple time-series togther.","metadata":{}},{"cell_type":"markdown","source":"Multiple time-series visualizations and code templates","metadata":{}},{"cell_type":"markdown","source":"> Analysing time-series in python","metadata":{}},{"cell_type":"code","source":"    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Time-Series Visualizations","metadata":{}},{"cell_type":"code","source":"# Plot all time series in the jobs DataFrame\n# ax = jobs.plot(colormap='Spectral', fontsize=6, linewidth=0.8)\n    \n# Set labels and legend\n# ax.set_xlabel('Date', fontsize=10)\n# ax.set_ylabel('Unemployment Rate', fontsize=10)\n# ax.set_title('Unemployment rate of U.S. workers by industry', fontsize=10)\n# ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n# Annotate your plots with vertical lines\n# ax.axvline('2001-07-01', color='blue', linestyle='--', linewidth=0.8)\n# ax.axvline('2008-09-01', color='blue', linestyle='--', linewidth=0.8)\n\n# Show plot\n# plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the seasonal values for the decomposition of each time series\n# for ts in jobs_names:\n#     jobs_seasonal[ts] = jobs_decomp[ts].seasonal\n    \n# Create a DataFrame from the jobs_seasonal dictionary\n# seasonality_df = pd.DataFrame.from_dict(jobs_seasonal)\n\n# Remove the label for the index\n# seasonality_df.index.name = None\n\n# Create a faceted plot of the seasonality_df DataFrame\n# seasonality_df.plot(subplots=True,\n#                    layout=(4, 4),\n#                    sharey=False,\n#                    fontsize=2,\n#                    linewidth=0.3,\n#                    legend=False)\n\n# Show plot\n# plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get correlation matrix of the seasonality_df DataFrame\n# seasonality_corr = seasonality_df.corr(method='spearman')\n\n# Customize the clustermap of the seasonality_corr correlation matrix\n# fig = sns.clustermap(seasonality_corr, annot=True, annot_kws={\"size\": 4}, linewidths=.4, figsize=(15, 10))\n# plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n# plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n# plt.show()\n\n# Print the correlation between the seasonalities of the Government and Education & Health industries\n# print(0.89)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Unlabelling the indices\n#The packages to be used are pandas, numpy, statsmodels and scipy for linear regression.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Probable questions to be asked\n#1. Do I need to resaqmple in my use-case?\n#2. Do I need to apply percent changes in my use-case?\n#3. ","metadata":{},"execution_count":null,"outputs":[]}]}